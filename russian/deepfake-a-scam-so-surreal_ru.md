---
title: Deepfake - очень сюрреалистическая афера
slug: deepfake
date: 17 декабря 2020
tags:
  - deepfake
  - rugpull
excerpt: Фейковые новости стары, как мир, но теперь они выглядят иначе. Технология дипфейк - это самая сюрреалистическая форма манипуляции средствами массовой информации, которую мы когда-либо видели. Она угрожает подорвать доверие нашему собственному восприятию. Когда есть основания сомневаться в наших собственных ощущениях, проверить что-либо становится практически невозможно.

banner: https://raw.githubusercontent.com/RektHQ/Assets/main/images/2020/12/headerEYE.jpg
---

![](https://raw.githubusercontent.com/RektHQ/Assets/main/images/2020/12/headerEYE.jpg)
**«Те, кто не хотят никого имитировать, ничего не создают»**

> Фейковые новости стары, как мир, но теперь они выглядят иначе.

Сложно представить себе, как можно этично использовать технологию, которая создавалась для обмана.

Технология дипфейк - это самая сюрреалистическая форма манипуляции средствами массовой информации, которую мы когда-либо видели. Она угрожает подорвать доверие нашему собственному восприятию. 

**Когда есть основания сомневаться в наших собственных ощущениях, проверить что-либо становится практически невозможно.**

Отсутствие доверия может быть так же разрушительно, как и доверие, оказанное по ошибке, заставляя людей в поляризованном обществе восставать друг против друга.

Информационная эра привела психологическую войну к нам в дом. Дезинформация, или сам факт того, что она существует значит, что мы сейчас боремся, чтобы отделить правду от лжи и рекламы. 

![](https://raw.githubusercontent.com/RektHQ/Assets/main/images/2020/12/image-2.png)

---

**Одна из недавних афер пролила свет на растущую проблему доверия и цифровой подлинности.**  

[DeTrade Fund](https://www.techtelegraph.co.uk/detrade-fund-new-cryptocurrency-fund-threatening-current-market-leaders/) представились общественным проектом, который предоставит пользователям доступ к арбитражным ботам на централизованных обменниках при условии, что у них будет достаточное количество токенов проекта - [DTF](https://etherscan.io/token/0x746adfded7d3996ad83b5ed5a68eea0993b541ee).

**DFT продавался на закрытой продаже, которая собрала 1,438 ETH, прежде чем компания испарилась с деньгами.**

To build trust from their users, this scam focused on building a fake identity with both on and offline presence. They registered a business with [Companies House](https://find-and-update.company-information.service.gov.uk/company/13063844) и подстроили выпуски [новостей](https://www.globenewswire.com/news-release/2020/12/09/2142436/0/en/DeTrade-Fund-New-Cryptocurrency-Fund-Threatening-Current-Market-Leaders.html) на [нескольких](https://uk.finance.yahoo.com/news/detrade-fund-cryptocurrency-fund-threatening-152100994.html) платформах, многократно показывая лицо и имя генерального директора «Mark Jensen».

**На рынке, заполненном анонимными, полностью онлайн проектами DeTrade выделялись своей «реальной» индивидуальностью.** Мошенники нажились на [доверии](https://www.sciencedaily.com/releases/2013/04/130402101249.htm), которое вызывает у нас человеческое лицо.

Когда пользователи узнали, что на закрытой продаже не продавалось ничего, кроме лжи, внимание переключилось на промо-ролики, которые DeTrade публиковали в соцсетях.

**Необычное поведение предполагаемого генерального директора DeTrade обратило на себя внимание, когда один из пользователей предположил, что он был на самом деле сгенерирован искусственным интеллектом.**

Полная ветка твитов находится [здесь.](https://twitter.com/DefiZeus/status/1337538434542563334)

![](https://lh4.googleusercontent.com/Z72rC7eqt_fJ0DXX-ikX44fwKixNgBKu4q6ba_60aIXvdDCIUHFyjo7HR-eIdzqLS_yHMHi7cNItv8mE4mf1YJUDcYi66YklpEzSwcLKsUsUvFgzUbuIofVvixvSOTXLd-QLjVuo)

> **Rekt связался с экспертом в этой области (IE), чтобы узнать, что он об этом думает.**

---

**IE:**

Меня зовут REDACTED, я генеральный директор REDACTED. Мы разрабатываем частные технологии на базе машинного обучения, чтобы автоматизировать создание и распространение развлекательного контента для взрослых. С точки зрения непрофессионала, мы разрабатываем ИИ, чтобы с его помощью создавать порно. В этой работе широко используются технологии дипфейк. А именно, мы изучаем, как с помощью дипфейков фотореалистично вставить в видео людей, сгенерированных ИИ. 

**rekt:**

_Расскажите нам о вашей работе в ИИ до того, как вы связали это с криптовалютами._

**IE:**

У нашей команды есть более чем десятилетний опыт в машинном обучении и компьютерном зрении, который мы применяли во всех отраслях. Но в основном мы разрабатывали решения для крупномасштабного сельского хозяйства и фармацевтики. 

**rekt:**

_Что вы подумали, когда впервые посмотрели видео DeTrade?_

**IE:**

Было много разговоров о том, что оно «сгенерировано ИИ» или что это дипфейк, или и то, и другое. Просмотрел его несколько раз. Есть вероятность, что это действительно дипфейк реального человека, но я почти уверен, что человек на видео не был сгенерирован ИИ. Я думаю, важно понять, в чем разница между этими двумя технологиями.

Мы в REDACTED натренировали генеративно-состязательную сеть (Generative adversarial network, GAN) для того, чтобы генерировать наших собственных людей, которые в реальности не существуют. Это в корне отличается от дипфейка.

**rekt:**

_Не могли бы вы объяснить, в чем разница между человеком, сгенерированным ИИ и дипфейком?_

**IE:**

Давайте сразу уясним, что технологии дипфейк используют искусственный интеллект. Но в технологии дипфейков ИИ не используется для того, чтобы создавать новый персонаж.   Вместо этого дипфейк берет уже существующий набор данных о лице человека, и накладывает его на лицо другого человека в уже готовом видео. Если все сделано правильно, то у вас должна получиться фотореалистичная и очень убедительная «замена лица». Видео, в котором человек делает что-то, чего он на самом деле не делал. В итоге, **дипфейки вообще не создают новую личность, а скорее используют накладывание уже существующего лица на другое видео.**  

С другой стороны, за «человеком, созданным ИИ», на видео или на неподвижной картинке стоит отдельный вид машинного обучения. Там ИИ дается большое количество данных в виде фотографий разных людей (обычно это генеративно-состязательная сеть или «GAN»), чтобы ИИ начал понимать, что такое «человек» или «тело». Когда ИИ получает достаточно таких данных, он может генерировать новые итерации людей на основании тех данных, которые ему показывали.  Этот вид ИИ является полной противоположностью дипфейков с точки зрения нашей сегодняшней беседы. Его нельзя использовать, чтобы вставить человека в видео, но он может создавать новых людей из воздуха.

**То, что я слышал касательно DeTrade, было обвинениями в том, что человек на видео был сгенерирован ИИ, и возможно еще и дипфейком, наложенным на реальное видео другого человека. Я хочу прояснить, что это почти наверняка не так.** 

**rekt:**

_Почему вы в этом так уверены?_

**IE:**

Дело в способностях. **Во всем мире есть, наверное, 5 компаний, которые могут генерировать фотореалистичного человека из ничего с помощью ИИ, а затем еще и вставить этого человека в  существующее видео, как то, что мы видели**, и сделать это настолько правдоподобно. Насколько я знаю, мы - одна из этих 5 компаний. Все остальные - многомиллиардные технологические компании типа Nvidia, или стартапы с очень хорошей репутацией, работающие с ИИ и с финансированием в десятки миллионов долларов. Мне кажется очень маловероятным, что руководители высшего звена в Nvidia будут выкраивать время в своем расписании, чтобы обокрасть сообщество DeFi на несколько миллионов баксов. 

Проясним этот момент: есть масса людей, которые могли вырезать лицо, которое вы видели на том видео из видео реального человека. Это мог быть учитель, ведущий урок в Zoom, или что-то в этом роде.

Но **теория, что это лицо было создано ИИ, практически невозможна.**

**rekt:**

_ИИ и дипфейк кажутся идеальными инструментами для нагнетания паранойи, многие люди подумают, что от них больше вреда, чем пользы. Как бы вы ответили на это?_

**IE:**

> **Честно говоря, я думаю, что  для паранойи есть основания.**

**Я считаю, что всем нужно свыкнуться с мыслью, что если вы видите фото, видео или слышите аудио человека, это еще не значит, что на видео действительно этот человек или что этот человек существует.**

Многие люди умом понимают это, но в то же время стремятся выбирать «не-анонимные команды», как если бы это дало им дополнительный уровень защиты в ходе инвестирования, если они увидят человека в прямом эфире или его фотографию с идентификацией. На самом деле это не так.

Прямо сейчас есть очень мало мест, где кто-то мог бы выкроить нового человека из куска ткани и создать видео с ним. Я горжусь, что наша компания входит в число этих мест. Но со временем увлекающимся любителям и даже мошенникам всегда становится все легче и легче воспроизводить эти технологии, и мы быстро приближаемся к такому моменту.

Все очень просто: нужно всегда брать в расчет, что, **пока вы не встретитесь с человеком лицом к лицу, вы никогда не сможете узнать, реальный ли он, и был ли это он на том видео, которое вы видели с ним, или же это была подделка.** Я считаю, что мы уже к этому пришли, и распространение этой технологии гарантирует, что со временем будет все важнее придерживаться такой философии. 

> **Если вы не пожали руку человеку, вы не можете быть уверенными в том, что он существует. А если вы не держали в руках его паспорт, вы не можете быть уверенными в том, что его личность тоже.**

![](https://raw.githubusercontent.com/RektHQ/Assets/main/images/2020/12/image-3.png)

**В эпоху информации, когда от точности средств информации зависит так много, мы больше не можем доверять тому, что мы видим или слышим.**

У инноваций всегда были [враги](https://en.wikipedia.org/wiki/Neo-Luddism); изменится ли наше мнение об этой технологии со временем?

Может быть, через двадцать лет мы поймем, что наше отвращение к дипфейкам было просто [технофобией](https://www.wired.com/story/weve-never-feared-tech-as-much-as-we-think-we-have/), а польза для общества перевешивает зло. Пресса сейчас делает этой технологии такую славу, что это будущее сложно представить.

Сальвадор Дали как-то сказал: «Si muero, no muero por todo», или «Если я умру, я не совсем умру.» 

Спустя тридцать лет после смерти его слова получают новый смысл в The Dali Museum. 
